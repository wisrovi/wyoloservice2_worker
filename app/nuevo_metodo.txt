    def log_model_and_metrics(self, trainer):
        """Log model and metrics to MLflow."""
        if "minio" in self.config and "mlflow" in self.config:
            # Generate registered model name from experiment and task info
            experiment_name = self.config.get("sweeper", {}).get(
                "study_name", "default_experiment"
            )
            task_id = self.config.get("task_id", "default_task")
            registered_model_name = f"{experiment_name}_{task_id}"

            # Log metrics first (simple and reliable)
            try:
                metrics = {
                    slugify(key): float(value) for key, value in trainer.metrics.items()
                }
                mlflow.log_metrics(metrics)
                print("✅ Training metrics logged successfully")
            except Exception as e:
                print(f"⚠️ Error logging metrics: {e}")

            # Log model metadata
            try:
                model_metadata = {
                    "model_type": "YOLO Classification",
                    "framework": "ultralytics",
                    "registered_model_name": registered_model_name,
                    "experiment_name": experiment_name,
                    "task_id": task_id,
                }
                for key, value in model_metadata.items():
                    mlflow.set_tag(key, value)
                print("✅ Model metadata logged")
            except Exception as meta_e:
                print(f"⚠️ Error logging model metadata: {meta_e}")

            # Log PyTorch model using MLflow's pytorch.log_model
            try:
                # Get the PyTorch model from trainer
                pytorch_model = trainer.model.model
                
                # Create a simple wrapper for MLflow compatibility
                class SimpleModelWrapper:
                    def __init__(self, model):
                        self.model = model
                    
                    def predict(self, data):
                        return self.model(data)
                    
                    def __call__(self, data):
                        return self.model(data)

                wrapped_model = SimpleModelWrapper(pytorch_model)

                # Log the model using pytorch.log_model
                pytorch.log_model(
                    wrapped_model,
                    name="yolo_model",
                    conda_env={
                        "channels": ["defaults", "pytorch", "conda-forge"],
                        "dependencies": [
                            "python=3.8",
                            "pytorch",
                            "torchvision",
                            "ultralytics",
                            "mlflow",
                            "numpy",
                            "pillow",
                            "pyyaml",
                        ],
                    },
                    registered_model_name=None,  # Don't auto-register
                )
                print("✅ PyTorch model logged successfully with pytorch.log_model")

                # Also log the .pt file as artifact for compatibility
                best_model_path = os.path.join(
                    str(trainer.save_dir), "weights", "best.pt"
                )
                if os.path.exists(best_model_path):
                    mlflow.log_artifact(best_model_path, "model_artifact")
                    print("✅ Model .pt file logged as artifact")

            except Exception as e:
                print(f"❌ Error logging PyTorch model: {e}")
                
                # Fallback: just log the .pt file as artifact
                try:
                    best_model_path = os.path.join(
                        str(trainer.save_dir), "weights", "best.pt"
                    )
                    if os.path.exists(best_model_path):
                        mlflow.log_artifact(best_model_path, "model_fallback")
                        print("⚠️ Model logged as fallback artifact")
                except Exception as fallback_e:
                    print(f"❌ Error in fallback logging: {fallback_e}")